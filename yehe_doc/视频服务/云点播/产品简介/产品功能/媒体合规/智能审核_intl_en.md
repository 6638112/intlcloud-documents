## Overview
The smart moderation feature can help you effectively recognize non-compliant content in audio, videos, and images. Smart content moderation can recognize erotic, violent, and illegal content in images, text, and speech. In addition, VOD supports custom moderation. You can create custom dictionaries and image libraries to recognize the custom non-compliant content. Based on advanced speech, text, and image recognition algorithms, this feature continuously performs training and modeling on massive amounts of non-compliant data to achieve industry-leading recognition accuracy and recall rate, guaranteeing your media content security.

## Use cases
As the multimedia industry develops, the media content becomes more diverse, and its production and spreading also become increasingly faster. However, the requirements for regulatory compliance have also become increasingly strict. This requires that media content operators moderate the compliance of their media assets. Effective content moderation should meet the following requirements:
- **Comprehensive**: The moderation rules must be comprehensive to meet the regulatory compliance requirements without any omissions.
- **Accurate**: The normal content cannot be falsely identified as non-compliant, and accurate details need to be provided for truly non-compliant content.
- **Quick**: As large amounts of media content are generated every day, the moderation must be quick so that compliant videos can be released quickly.

Smart content moderation has the following use cases:

<table>
    <tr>
        <th>
            Scenario               
        </th>
				<th>
           Description
        </th>
    </tr>
 <tr>
        <td>
            Social media platforms
        </td>
				<td>
            Social media platforms, including forums, short video platforms, and vlogs, are primarily comprised of user-generated content (UGC).<br/>
						<li>Characteristics: Fast update, large quantity, and diverse content.</li>
						<li>Challenges: Users want their content to be released immediately, but traditional manual moderation can hardly satisfy the requirements for quick moderation.</li>
        </td>
 </tr>
 <tr>
        <td>
            Live stream recording
        </td>
				<td>
            Live streams can be delivered again after they are recorded and saved. The sources of live streaming content are diverse, including online education, shopping, and entertainment industries.<br/>
						<li>Characteristics: Long videos, typically several hours or even dozens of hours long. The media content involves trending events in various industries.</li>
						<li>Challenges: The media content is very large in size. Traditional manual moderation tends to miss non-compliant segments and involves a lengthy process with a low moderation quality and low efficiency.</li>
        </td>
 </tr>
 <tr>
        <td>
            Video platforms
        </td>
				<td>
            Professional content production platforms, such as online video portal websites.<br/>
						<li>Characteristics: Long videos with professional production quality.</li>
						<li>Challenges: In traditional manual moderation, non-compliant video segments are labeled by human reviewers, which results in a lengthy moderation process and makes it difficult to release trending videos in time.</br>In addition, misjudgments often occur with manual moderation of professional content, so non-compliant content can still be released and may cause complaints.</li>
        </td>
 </tr>
</table>

## Directions
For more information, see:
- [How to Audit Video Content](https://intl.cloud.tencent.com/document/product/266/37547).
- [Audio/Video Content Moderation](https://intl.cloud.tencent.com/document/product/266/33944).
