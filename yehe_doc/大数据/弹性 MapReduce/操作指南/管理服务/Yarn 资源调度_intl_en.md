## Feature Overview
YARN Resource Scheduling supports interactive YARN resource queue scheduling management, which is more convenient than file-based configuration management. Currently, it supports two types of scheduling configurations: Fair Scheduler and Capacity Scheduler.
- Fair Scheduler allocates resources fairly to each job on YARN based on weight.
- Capacity Scheduler organizes resources in a hierarchical manner, allowing multiple users to share cluster resources based on multi-level resource restrictions.

>!
>- Fair Scheduler is used by default. Therefore, you need to configure relevant parameters in the `fair-scheduler.xml` configuration file for the YARN component. If you switch >to Capacity Scheduler, configure relevant parameters in the `capacity-scheduler.xml` configuration file. No matter which scheduler you use, parameter configurations must be >consistent with those on the **Resource Scheduling** page.
>- After setting the policy on the **Resource Scheduling** page, you need to click **Refresh Dynamic Resource Pools** to deliver the policy configurations to keep the >configuration file and parameters consistent in **Configuration Management**. After deleting a resource pool, you need to manually restart or click **Apply** to restart >Resource Manager.
>- After switching schedulers, you need to click **Apply** to restart Resource Manager for the changes to take effect.

## Configuring Fair Scheduler
1. Log in to the [EMR console](https://console.cloud.tencent.com/emr) and click a Hadoop cluster ID on the cluster list to go to the cluster details page.
2. On the cluster details page, click **Cluster Service** > **Operation** on the **YARN** component card > **Resource Scheduling** to go to the resource scheduling page.
![](https://main.qcloudimg.com/raw/b4f005fcac189865fbd03d45f7374ca9.png)
3. Turn on **Resource Scheduler**, then you can configure the scheduler.
![](https://main.qcloudimg.com/raw/649ff7eea0362afb9e91dfd5b05386cb.png)
4. Create a resource pool for Fair Scheduler.
Select **Fair Scheduler** and click **Create Resource Pool** to create a resource pool. You can also edit, clone, delete an existing resource pool as well as create a subpool for it.
![](https://main.qcloudimg.com/raw/75fa2e6b9daa408bb3ff57fa066ce2c7.png)
**Fields and parameters**
<table>
<thead>
<tr>
<th><strong>Field</strong></th>
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Resource Pool Name</td>
<td>`name`</td>
<td>Name of the resource pool or queue</td>
</tr>
<tr>
<td>Parent Pool</td>
<td>The value of `type` is `parent`.</td>
<td>Means that although the resource pool has no subpools, it is not a leaf node. A parent pool cannot have subpools in Hadoop v2.8 and later.</td>
</tr>
<tr>
<td>Configuration Set</td>
<td>None</td>
<td>YARN does not have this parameter, which means a collection of scheduled tasks.</td>
</tr>
<tr>
<td>Weight</td>
<td>`weight`</td>
<td>Percentage of resources in the parent pool. A greater weight means more resources allocated.</td>
</tr>
<tr>
<td>Min Resources</td>
<td>minResources</td>
<td>The minimum amount of resources guaranteed. When the minimum amount of resources guaranteed for a queue is not met, it has a higher priority than other queues at the same level to obtain resources.</td>
</tr>
<tr>
<td>Max Resources</td>
<td>maxResources</td>
<td>The maximum amount of resources that can be used. The amount of resources available for each queue cannot exceed this value.</td>
</tr>
<tr>
<td>Max Concurrent Running Apps</td>
<td>maxRunningApps</td>
<td>The maximum number of concurrent running applications allowed. This limitation can prevent intermediate outputs generated by excessive concurrent running map tasks from filling up the disks.</td>
</tr>
<tr>
<td>Max Share for App Master</td>
<td>maxAMShare</td>
<td>The maximum percentage of resources that can be used to run Application Master. This attribute only applies to leaf queues.</td>
</tr>
<tr>
<td>Scheduling Policy</td>
<td>schedulingPolicy</td>
<td>You can set a scheduling policy for any queue. Valid values include `Fifo`, `Fair`, and `Drf`. If the value is `Fifo` or `Fair`, only memory is taken into account in resource allocation. If `Drf`, both memory and the number of cores are taken into account.</td>
</tr>
<tr>
<td>Preemption Mode</td>
<td>allowPreemptionFrom</td>
<td>This field applies only to Hadoop v3.x and later. In v2.x, you can only configure `yarn.scheduler.fair.preemption` to set the preemption mode.</td>
</tr>
<tr>
<td>Fair Share Preemption Threshold</td>
<td>fairSharePreemptionThreshold</td>
<td>The fair share preemption threshold for the queue. If the queue waits `fairSharePreemptionTimeout` without receiving `fairSharePreemptionThreshold*fairShare` resources, it is allowed to preempt resources from other queues. If this field is not set, the queue will inherit the value from its parent queue.</td>
</tr>
<tr>
<td>Fair Share Preemption Timeout</td>
<td>fairSharePreemptionTimeout</td>
<td>Number of seconds the queue is under its fair share threshold before it will try to preempt resources from other queues. If this field is not set, the queue will inherit the value from its parent queue.</td>
</tr>
<tr>
<td>Min Share Preemption Timeout</td>
<td>minSharePreemptionTimeout</td>
<td>Number of seconds the queue is under its minimum share before it will try to preempt resources from other queues. If this field is not set, the queue will inherit the value from its parent queue.</td>
</tr>
<tr>
<td>Submission</td>
<td>aclSubmitApps</td>
<td>List of users that can submit apps to the queue</td>
</tr>
<tr>
<td>Management</td>
<td>aclAdministerApps</td>
<td>List of users that can manage the queue</td>
</tr>
</tbody></table>
5. Configure execution plans.
In the **Policy Settings** section, click **Execution Plans** > **Create Execution Plan** to create an execution plan.
![](https://main.qcloudimg.com/raw/674b6ee1c251bec1df8794731e52f235.png)![](https://main.qcloudimg.com/raw/69e7149292d7df16bf66c6e2a1279cdf.png)
6. Configure placement rules.
In the **Policy Settings** section, click **Placement Rules** > **Create Placement Rule** to create a placement rule.
![](https://main.qcloudimg.com/raw/e9a1aa2f8c2dccde003eb429dc899678.png)
7. Configure user limits.
In the **Policy Settings** section, click **User Limits** > **Create User Limit** to create a user limit.
![](https://main.qcloudimg.com/raw/890adb0479418227f7df1e53d2671565.png)![](https://main.qcloudimg.com/raw/e11d0b9cdec52b1992c43d055b47b212.png)

## Configuring Capacity Scheduler
1. Log in to the [EMR console](https://console.cloud.tencent.com/emr) and click a Hadoop cluster ID on the cluster list to go to the cluster details page.
2. On the cluster details page, click **Cluster Service** > **Operation** on the **YARN** component card > **Resource Scheduling** to go to the resource scheduling page.
![](https://main.qcloudimg.com/raw/943c5a6a90a3373f850b8229d69c1f2a.png)
3. Turn on **Resource Scheduler**, then you can configure the scheduler.
4. Create a resource pool for Capacity Scheduler.
Select **Capacity Scheduler** and click **Create Resource Pool** to create a resource pool. You can also edit, clone, delete an existing resource pool as well as create a subpool for it.
![](https://main.qcloudimg.com/raw/be26fc25498e4d3775519a3c04656759.png)![](https://main.qcloudimg.com/raw/f9ba09c74eb6c8ff13658cd55a40b3be.png)
**Fields and parameters**
<table>
<thead>
<tr>
<th><strong>Field</strong></th>
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Resource Pool Name</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.queues</code></td>
<td>Name of the resource pool or queue</td>
</tr>
<tr>
<td>Capacity</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.capacity</code></td>
<td>Percentage of the queue's capacity in the cluster. The sum of capacities for all queues must be equal to 100%. However, the queue can consume more resources than the queue's capacity if there are free resources in other queues.</td>
</tr>
<tr>
<td>Max Capacity</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.maximum-capacity</code></td>
<td>Maximum queue capacity in percentage. Because of resource sharing, the amount of resources used by a queue may exceed its capacity, and this field specifies the maximum amount of resources that can be used by the queue.</td>
</tr>
<tr>
<td>Min User Capacity</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.minimum-user-limit-percent</code></td>
<td>Minimum resources in percentage guaranteed for each user. Each queue enforces a limit on the percentage of resources allocated to a user at any given time. When multiple users' applications are running in a queue concurrently, the amount of resources used by each user varies between a minimum and maximum value. The minimum value depends on the number of running applications, and the maximum value is determined by `minimum-user-limit-percent`.</td>
</tr>
<tr>
<td>User Resource Factor</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.user-limit-factor</code></td>
<td>Maximum amount of resources in percentage that can be used by each user. For example, if the value is `30`, the amount of resources for each user cannot exceed 30% of the queue capacity at any given time.</td>
</tr>
<tr>
<td>Max Memory per Container</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.maximum-allocation-mb</code></td>
<td>Maximum memory that can be allocated to each container. The value will overwrite and cannot be greater than that of the system's `yarn.scheduler.maximum-allocation-mb`.</td>
</tr>
<tr>
<td>Resource Pool Status</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.state</code></td>
<td>Status of the queue. The value can be `Running` or `Stopped`. If a queue is in the `Stopped` status, new applications cannot be submitted to it or any of its subqueues.</td>
</tr>
<tr>
<td>Max Apps</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.maximum-applications</code></td>
<td>Maximum number of concurrent active (both running and pending) applications allowed in the system </td>
</tr>
<tr>
<td>Max Resources for AM</td>
<td><code>yarn.scheduler.capacity.&lt;queue-path&gt;.maximum-am-resource-percent</code></td>
<td>Maximum percentage of resources in the cluster which can be used to run application masters. It controls the number of concurrent active applications. </td>
</tr>
<tr>
<td>Submission</td>
<td><code>yarn.scheduler.capacity.root.&lt;queue-path&gt;.acl_submit_applications</code></td>
<td>List of users that can submit apps to the queue</td>
</tr>
<tr>
<td>Management</td>
<td><code>yarn.scheduler.capacity.root.&lt;queue-path&gt;.acl_administer_queue</code></td>
<td>List of users that can manage the queue</td>
</tr>
</tbody></table>
5. Configure resource pool mappings.
In the **Policy Settings** section, click **Resource Pool Mappings** > **Create Resource Pool Mapping** to create a resource pool mapping.
![](https://main.qcloudimg.com/raw/6973f8f7f454536ac3552d2a16fd1120.png)![](https://main.qcloudimg.com/raw/b0221c21f9993dce769cb47af678d21d.png)
6. Configure **Overwrite Specified Queues**.
This feature is disabled by default. For example, you have defined a mapped queue in **Resource Pool Mappings** and specified a queue other than the mapped queue when submitting a task; if the specified queue is `default` and **Overwrite Specified Queues** is enabled, the mapped queue will be used; otherwise, the specified queue will be used.
![](https://main.qcloudimg.com/raw/06e385c7f36136875227072001c8c82a.png)

